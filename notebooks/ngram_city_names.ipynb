{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0d5e2524",
      "metadata": {},
      "source": [
        "This notebook aims to teach:\n",
        "\n",
        "How to build a simple autoregressive generative model that produces names resembling cities from around the world\n",
        "\n",
        "How increasing context size (bigram → trigram → 4-gram) leads to lower model loss and improved predictions\n",
        "\n",
        "How a bigram model can be implemented using a traditional, rule-based software approach"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "064dbe15",
      "metadata": {},
      "source": [
        "---------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "146d9935",
      "metadata": {},
      "source": [
        "1. Lets create a generative model which can generate new city names\n",
        "\n",
        "- Cities dataset consists of existing city names around the world - lets take a peek at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5f4233db",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Encamp</td>\n",
              "      <td>Andorra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Canillo</td>\n",
              "      <td>Andorra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sharjah</td>\n",
              "      <td>United Arab Emirates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dubai</td>\n",
              "      <td>United Arab Emirates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Asadabad</td>\n",
              "      <td>Afghanistan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       city               country\n",
              "0    Encamp               Andorra\n",
              "1   Canillo               Andorra\n",
              "2   Sharjah  United Arab Emirates\n",
              "3     Dubai  United Arab Emirates\n",
              "4  Asadabad           Afghanistan"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"../dataset/cities_latin_alphabet.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77912866",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We have 35320 city names from 185 countries\n",
            "City Names by Country:\n",
            "country\n",
            "Russia           3768\n",
            "Philippines      3161\n",
            "United States    2929\n",
            "Name: city, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "city_counts_by_country = df.groupby(\"country\")[\"city\"].count().sort_values(ascending=False).head(3)\n",
        "\n",
        "\n",
        "print(f'We have {len(df)} city names from {len(set(df[\"country\"]))} countries')\n",
        "\n",
        "print('City Names by Country:')\n",
        "print(city_counts_by_country)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95381416",
      "metadata": {},
      "source": [
        "We will generate new city names using a character level model\n",
        "- Lets generate a vocabulary consiting of characters from city names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "730c9fa7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "we have a vocabulary of 66 characters\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "# vocab should be all characters from df[city] lowercase\n",
        "all_cities = df[\"city\"].astype(str).str.lower()\n",
        "vocab = sorted(set(\"\".join(all_cities)))\n",
        "V = len(vocab)\n",
        "\n",
        "print(f'we have a vocabulary of {V} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "295fdf87",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' ',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '9',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " 'à',\n",
              " 'á',\n",
              " 'â',\n",
              " 'ã',\n",
              " 'ä',\n",
              " 'å',\n",
              " 'æ',\n",
              " 'ç',\n",
              " 'è',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'ë',\n",
              " 'ì',\n",
              " 'í',\n",
              " 'î',\n",
              " 'ï',\n",
              " 'ñ',\n",
              " 'ò',\n",
              " 'ó',\n",
              " 'ô',\n",
              " 'õ',\n",
              " 'ö',\n",
              " 'ø',\n",
              " 'ù',\n",
              " 'ú',\n",
              " 'û',\n",
              " 'ü',\n",
              " 'ý']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03ded0f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "stoi = {char: idx for idx, char in enumerate(vocab)}\n",
        "itos = {idx: char for char, idx in stoi.items()}\n",
        "\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s]\n",
        "def decode(ids):\n",
        "    return ''.join([itos[i] for i in ids])\n",
        "    \n",
        "df['city_with_ending'] = df['city'].astype(str) + '.'\n",
        "names = df[df['country'] == 'Russia']['city_with_ending']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8a87a071",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class BigramMLP(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, 128)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)   # (B, 128)\n",
        "        return self.mlp(x) # (B, V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b9215b3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BigramMLP(\n",
            "  (embed): Embedding(66, 128)\n",
            "  (mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=66, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model= BigramMLP(V)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d77bf864",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'aâä.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def generate(model, start_char, max_len=20):\n",
        "    idx = torch.tensor([stoi[start_char]])\n",
        "    out = start_char\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        logits = model(idx)\n",
        "        probs = F.softmax(logits[-1], dim=-1)\n",
        "        next_idx = torch.multinomial(probs, 1).item()\n",
        "        next_char = itos[next_idx]\n",
        "        out += next_char\n",
        "        if next_char == '.':\n",
        "            break\n",
        "        idx = torch.tensor([next_idx])\n",
        "\n",
        "    return out\n",
        "\n",
        "generate(BigramMLP(V), 'a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76892890",
      "metadata": {},
      "outputs": [],
      "source": [
        "# names = df['city_with_ending']\n",
        "X, Y = [], []\n",
        "\n",
        "for name in names:\n",
        "    name = name.lower()\n",
        "    for a, b in zip(name[:-1], name[1:]):\n",
        "\n",
        "        X.append(stoi[a])\n",
        "        Y.append(stoi[b])\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n",
        "\n",
        "model = BigramMLP(V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd3141c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BigramMLP(V)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bab2327",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BigramMLP(V)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4713d77f",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BigramMLP(V)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ac78dfb1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0 | loss 4.1721\n",
            "step 500 | loss 2.4007\n",
            "step 1000 | loss 2.3299\n",
            "step 1500 | loss 2.3393\n",
            "step 2000 | loss 2.3477\n",
            "step 2500 | loss 2.4110\n",
            "step 3000 | loss 2.3692\n",
            "step 3500 | loss 2.4215\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "steps = 4000\n",
        "\n",
        "for step in range(steps):\n",
        "    idx = torch.randint(0, len(X), (batch_size,))\n",
        "    xb = X[idx]\n",
        "    yb = Y[idx]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(xb)\n",
        "    loss = loss_fn(logits, yb)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 500 == 0:\n",
        "        print(f\"step {step} | loss {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d90fbd53",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'skintogol.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(model, 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa6a3f0",
      "metadata": {},
      "source": [
        "# Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "773fa5f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TrigramMLP(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, 128)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(128 * 2, 256),  # two embeddings concatenated\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 2)\n",
        "        emb = self.embed(x)          # (B, 2, 128)\n",
        "        emb = emb.view(x.size(0), -1)  # (B, 256)\n",
        "        return self.mlp(emb)         # (B, V)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "51c2f50a",
      "metadata": {},
      "outputs": [],
      "source": [
        "X, Y = [], []\n",
        "\n",
        "for name in names:\n",
        "    name = name.lower()\n",
        "    for a, b, c in zip(name[:-2], name[1:-1], name[2:]):\n",
        "        X.append([stoi[a], stoi[b]])\n",
        "        Y.append(stoi[c])\n",
        "\n",
        "X = torch.tensor(X)  # (N, 2)\n",
        "Y = torch.tensor(Y)  # (N,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "96d5fe83",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0 | loss 4.1820\n",
            "step 500 | loss 2.0225\n",
            "step 1000 | loss 1.9467\n",
            "step 1500 | loss 1.9289\n",
            "step 2000 | loss 1.9248\n",
            "step 2500 | loss 1.8935\n",
            "step 3000 | loss 1.8825\n",
            "step 3500 | loss 1.8225\n"
          ]
        }
      ],
      "source": [
        "model = TrigramMLP(V)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
        "\n",
        "batch_size = 256\n",
        "steps = 4000\n",
        "\n",
        "for step in range(steps):\n",
        "    idx = torch.randint(0, len(X), (batch_size,))\n",
        "    xb = X[idx]   # (B, 2)\n",
        "    yb = Y[idx]   # (B,)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(xb)\n",
        "    loss = loss_fn(logits, yb)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 500 == 0:\n",
        "        print(f\"step {step} | loss {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c704fe92",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(model, start_chars, max_len=20):\n",
        "    assert len(start_chars) == 2\n",
        "\n",
        "    idx = [stoi[start_chars[0]], stoi[start_chars[1]]]\n",
        "    out = start_chars\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        x = torch.tensor([idx])  # (1, 2)\n",
        "        logits = model(x)\n",
        "        probs = F.softmax(logits[0], dim=-1)\n",
        "\n",
        "        next_idx = torch.multinomial(probs, 1).item()\n",
        "        next_char = itos[next_idx]\n",
        "\n",
        "        out += next_char\n",
        "        if next_char == '.':\n",
        "            break\n",
        "\n",
        "        idx = [idx[1], next_idx]  # slide window\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "5d25f7df",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'caltula.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(model, 'ca')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b9e9bdc",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3fac7014",
      "metadata": {},
      "source": [
        "# 4-gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "a0f9263f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FourGramMLP(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 4, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 4)\n",
        "        emb = self.embed(x)            # (B, 4, 128)\n",
        "        emb = emb.view(x.size(0), -1)  # (B, 512)\n",
        "        return self.mlp(emb)           # (B, V)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "5ae725d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "X, Y = [], []\n",
        "\n",
        "for name in names:\n",
        "    name = name.lower()\n",
        "    if len(name) < 5:\n",
        "        continue\n",
        "\n",
        "    for a, b, c, d, e in zip(\n",
        "        name[:-4], name[1:-3], name[2:-2], name[3:-1], name[4:]\n",
        "    ):\n",
        "        X.append([stoi[a], stoi[b], stoi[c], stoi[d]])\n",
        "        Y.append(stoi[e])\n",
        "\n",
        "X = torch.tensor(X)  # (N, 4)\n",
        "Y = torch.tensor(Y)  # (N,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "4ee5b1d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0 | loss 4.2170\n",
            "step 500 | loss 1.2249\n",
            "step 1000 | loss 1.1516\n",
            "step 1500 | loss 0.7939\n",
            "step 2000 | loss 0.8417\n",
            "step 2500 | loss 0.7926\n",
            "step 3000 | loss 0.8238\n",
            "step 3500 | loss 0.7599\n"
          ]
        }
      ],
      "source": [
        "model = FourGramMLP(V)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
        "\n",
        "batch_size = 256\n",
        "steps = 4000\n",
        "\n",
        "for step in range(steps):\n",
        "    idx = torch.randint(0, len(X), (batch_size,))\n",
        "    xb = X[idx]   # (B, 4)\n",
        "    yb = Y[idx]   # (B,)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(xb)\n",
        "    loss = loss_fn(logits, yb)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 500 == 0:\n",
        "        print(f\"step {step} | loss {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "c4fe3978",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(model, start_text, max_len=50):\n",
        "    assert len(start_text) >= 4\n",
        "\n",
        "    context = [stoi[c] for c in start_text[-4:]]\n",
        "    out = start_text\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        x = torch.tensor([context])  # (1, 4)\n",
        "        logits = model(x)\n",
        "        probs = F.softmax(logits[0], dim=-1)\n",
        "\n",
        "        next_idx = torch.multinomial(probs, 1).item()\n",
        "        next_char = itos[next_idx]\n",
        "\n",
        "        out += next_char\n",
        "        if next_char == '.':\n",
        "            break\n",
        "\n",
        "        context = context[1:] + [next_idx]\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "98fec8e6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'casalimbay.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(model, 'casa')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d0dd5b07",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique bigrams: 511\n",
            "\n",
            "Top 20 most common character bigrams:\n",
            "  'sk': 1324\n",
            "  'a.': 1033\n",
            "  'ov': 1009\n",
            "  'ka': 800\n",
            "  'y.': 763\n",
            "  'ya': 761\n",
            "  'no': 719\n",
            "  'vo': 677\n",
            "  'ko': 638\n",
            "  'ye': 621\n",
            "  'ki': 618\n",
            "  'o.': 599\n",
            "  'in': 548\n",
            "  'ay': 515\n",
            "  'k.': 512\n",
            "  'iy': 497\n",
            "  'sh': 471\n",
            "  'oy': 466\n",
            "  'ch': 463\n",
            "  'an': 451\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count character bigrams from city names\n",
        "bigram_counts = Counter()\n",
        "\n",
        "for name in names:\n",
        "    name_lower = name.lower()\n",
        "    # Create bigrams by pairing consecutive characters\n",
        "    for i in range(len(name_lower) - 1):\n",
        "        bigram = name_lower[i:i+2]\n",
        "        bigram_counts[bigram] += 1\n",
        "\n",
        "# Display most common bigrams\n",
        "print(f\"Total unique bigrams: {len(bigram_counts)}\")\n",
        "print(f\"\\nTop 20 most common character bigrams:\")\n",
        "for bigram, count in bigram_counts.most_common(20):\n",
        "    print(f\"  '{bigram}': {count}\")\n",
        "\n",
        "# Convert to dictionary for easy access\n",
        "bigram_dict = dict(bigram_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42f04b12",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_from_bigram_dict(start_char, max_len=20):\n",
        "    \"\"\"\n",
        "    Generate text using bigram dictionary counts.\n",
        "    Selects next character based on bigram frequency.\n",
        "    \"\"\"\n",
        "    if start_char not in vocab:\n",
        "        return f\"Error: '{start_char}' not in vocabulary\"\n",
        "    \n",
        "    output = start_char\n",
        "    current_char = start_char.lower()\n",
        "    \n",
        "    for _ in range(max_len):\n",
        "        # Find all bigrams that start with current_char\n",
        "        possible_bigrams = [(bigram, count) for bigram, count in bigram_dict.items() \n",
        "                           if bigram[0] == current_char]\n",
        "        \n",
        "        if not possible_bigrams:\n",
        "            # No bigrams found starting with this character, stop\n",
        "            break\n",
        "        \n",
        "        # Extract next characters and their counts\n",
        "        next_chars = []\n",
        "        weights = []\n",
        "        for bigram, count in possible_bigrams:\n",
        "            next_char = bigram[1]\n",
        "            next_chars.append(next_char)\n",
        "            weights.append(count)\n",
        "        \n",
        "        # Weighted random selection based on bigram counts\n",
        "        next_char = random.choices(next_chars, weights=weights, k=1)[0]\n",
        "        output += next_char\n",
        "        \n",
        "        # Stop if we hit the end marker\n",
        "        if next_char == '.':\n",
        "            break\n",
        "        \n",
        "        current_char = next_char\n",
        "    \n",
        "    return output\n",
        "\n",
        "# Test generation\n",
        "print(\"Generating city names using bigram dictionary:\")\n",
        "for start in ['m', 's', 'k', 'n', 'v']:\n",
        "    generated = generate_from_bigram_dict(start)\n",
        "    print(f\"  '{start}' -> '{generated}'\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
