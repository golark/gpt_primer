{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733f76d5",
   "metadata": {},
   "source": [
    "GPTs learn math by predicting the next valid solution step, exactly like predicting the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4233db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>11224</td>\n",
       "      <td>42.533333</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>[42.5333333, 1.5833333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Les Escaldes</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>15854</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>[42.5000000, 1.5333333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>20430</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>1.516667</td>\n",
       "      <td>[42.5000000, 1.5166667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>7211</td>\n",
       "      <td>42.550000</td>\n",
       "      <td>1.516667</td>\n",
       "      <td>[42.5500000, 1.5166667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Canillo</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>3292</td>\n",
       "      <td>42.566667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>[42.5666667, 1.6000000]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              city  country  population   latitude  longitude  \\\n",
       "0           0            Encamp  Andorra       11224  42.533333   1.583333   \n",
       "1           1      Les Escaldes  Andorra       15854  42.500000   1.533333   \n",
       "2           2  Andorra la Vella  Andorra       20430  42.500000   1.516667   \n",
       "3           3        La Massana  Andorra        7211  42.550000   1.516667   \n",
       "4           4           Canillo  Andorra        3292  42.566667   1.600000   \n",
       "\n",
       "          city coordinates  \n",
       "0  [42.5333333, 1.5833333]  \n",
       "1  [42.5000000, 1.5333333]  \n",
       "2  [42.5000000, 1.5166667]  \n",
       "3  [42.5500000, 1.5166667]  \n",
       "4  [42.5666667, 1.6000000]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../dataset/Cities.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77912866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "Russia           4324\n",
      "United States    4171\n",
      "Philippines      3752\n",
      "India            2995\n",
      "Romania          2755\n",
      "Brazil           2017\n",
      "Mexico           1687\n",
      "Germany          1478\n",
      "Italy            1118\n",
      "Greece           1084\n",
      "Name: city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "city_counts = df.groupby(\"country\")[\"city\"].count().sort_values(ascending=False).head(10)\n",
    "print(city_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ded0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "# vocab should be all characters from df[city] lowercase\n",
    "all_cities = df[\"city\"].astype(str).str.lower()\n",
    "vocab = sorted(set(\"\".join(all_cities)))\n",
    "V = len(vocab)\n",
    "\n",
    "stoi = {char: idx for idx, char in enumerate(vocab)}\n",
    "itos = {idx: char for char, idx in stoi.items()}\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "def decode(ids):\n",
    "    return ''.join([itos[i] for i in ids])\n",
    "    \n",
    "df['city_with_ending'] = df['city'].astype(str) + '.'\n",
    "names = df[df['country'] == 'Russia']['city_with_ending']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a87a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BigramMLP(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, 128)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, vocab_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)   # (B, 128)\n",
    "        return self.mlp(x) # (B, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77bf864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aâä.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(model, start_char, max_len=20):\n",
    "    idx = torch.tensor([stoi[start_char]])\n",
    "    out = start_char\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        logits = model(idx)\n",
    "        probs = F.softmax(logits[-1], dim=-1)\n",
    "        next_idx = torch.multinomial(probs, 1).item()\n",
    "        next_char = itos[next_idx]\n",
    "        out += next_char\n",
    "        if next_char == '.':\n",
    "            break\n",
    "        idx = torch.tensor([next_idx])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "generate(BigramMLP(V), 'a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76892890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# names = df['city_with_ending']\n",
    "X, Y = [], []\n",
    "\n",
    "for name in names:\n",
    "    name = name.lower()\n",
    "    for a, b in zip(name[:-1], name[1:]):\n",
    "\n",
    "        X.append(stoi[a])\n",
    "        Y.append(stoi[b])\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "model = BigramMLP(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4713d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramMLP(V)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac78dfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | loss 4.1721\n",
      "step 500 | loss 2.4007\n",
      "step 1000 | loss 2.3299\n",
      "step 1500 | loss 2.3393\n",
      "step 2000 | loss 2.3477\n",
      "step 2500 | loss 2.4110\n",
      "step 3000 | loss 2.3692\n",
      "step 3500 | loss 2.4215\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "steps = 4000\n",
    "\n",
    "for step in range(steps):\n",
    "    idx = torch.randint(0, len(X), (batch_size,))\n",
    "    xb = X[idx]\n",
    "    yb = Y[idx]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(xb)\n",
    "    loss = loss_fn(logits, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(f\"step {step} | loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d90fbd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skintogol.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa6a3f0",
   "metadata": {},
   "source": [
    "# Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "773fa5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TrigramMLP(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, 128)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(128 * 2, 256),  # two embeddings concatenated\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, vocab_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 2)\n",
    "        emb = self.embed(x)          # (B, 2, 128)\n",
    "        emb = emb.view(x.size(0), -1)  # (B, 256)\n",
    "        return self.mlp(emb)         # (B, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51c2f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "for name in names:\n",
    "    name = name.lower()\n",
    "    for a, b, c in zip(name[:-2], name[1:-1], name[2:]):\n",
    "        X.append([stoi[a], stoi[b]])\n",
    "        Y.append(stoi[c])\n",
    "\n",
    "X = torch.tensor(X)  # (N, 2)\n",
    "Y = torch.tensor(Y)  # (N,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96d5fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | loss 4.1820\n",
      "step 500 | loss 2.0225\n",
      "step 1000 | loss 1.9467\n",
      "step 1500 | loss 1.9289\n",
      "step 2000 | loss 1.9248\n",
      "step 2500 | loss 1.8935\n",
      "step 3000 | loss 1.8825\n",
      "step 3500 | loss 1.8225\n"
     ]
    }
   ],
   "source": [
    "model = TrigramMLP(V)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "batch_size = 256\n",
    "steps = 4000\n",
    "\n",
    "for step in range(steps):\n",
    "    idx = torch.randint(0, len(X), (batch_size,))\n",
    "    xb = X[idx]   # (B, 2)\n",
    "    yb = Y[idx]   # (B,)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(xb)\n",
    "    loss = loss_fn(logits, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(f\"step {step} | loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c704fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, start_chars, max_len=20):\n",
    "    assert len(start_chars) == 2\n",
    "\n",
    "    idx = [stoi[start_chars[0]], stoi[start_chars[1]]]\n",
    "    out = start_chars\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        x = torch.tensor([idx])  # (1, 2)\n",
    "        logits = model(x)\n",
    "        probs = F.softmax(logits[0], dim=-1)\n",
    "\n",
    "        next_idx = torch.multinomial(probs, 1).item()\n",
    "        next_char = itos[next_idx]\n",
    "\n",
    "        out += next_char\n",
    "        if next_char == '.':\n",
    "            break\n",
    "\n",
    "        idx = [idx[1], next_idx]  # slide window\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d25f7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caltula.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, 'ca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e9bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fac7014",
   "metadata": {},
   "source": [
    "# 4-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0f9263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FourGramMLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, vocab_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 4)\n",
    "        emb = self.embed(x)            # (B, 4, 128)\n",
    "        emb = emb.view(x.size(0), -1)  # (B, 512)\n",
    "        return self.mlp(emb)           # (B, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ae725d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "for name in names:\n",
    "    name = name.lower()\n",
    "    if len(name) < 5:\n",
    "        continue\n",
    "\n",
    "    for a, b, c, d, e in zip(\n",
    "        name[:-4], name[1:-3], name[2:-2], name[3:-1], name[4:]\n",
    "    ):\n",
    "        X.append([stoi[a], stoi[b], stoi[c], stoi[d]])\n",
    "        Y.append(stoi[e])\n",
    "\n",
    "X = torch.tensor(X)  # (N, 4)\n",
    "Y = torch.tensor(Y)  # (N,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ee5b1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | loss 4.2170\n",
      "step 500 | loss 1.2249\n",
      "step 1000 | loss 1.1516\n",
      "step 1500 | loss 0.7939\n",
      "step 2000 | loss 0.8417\n",
      "step 2500 | loss 0.7926\n",
      "step 3000 | loss 0.8238\n",
      "step 3500 | loss 0.7599\n"
     ]
    }
   ],
   "source": [
    "model = FourGramMLP(V)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "batch_size = 256\n",
    "steps = 4000\n",
    "\n",
    "for step in range(steps):\n",
    "    idx = torch.randint(0, len(X), (batch_size,))\n",
    "    xb = X[idx]   # (B, 4)\n",
    "    yb = Y[idx]   # (B,)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(xb)\n",
    "    loss = loss_fn(logits, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(f\"step {step} | loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4fe3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, start_text, max_len=50):\n",
    "    assert len(start_text) >= 4\n",
    "\n",
    "    context = [stoi[c] for c in start_text[-4:]]\n",
    "    out = start_text\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        x = torch.tensor([context])  # (1, 4)\n",
    "        logits = model(x)\n",
    "        probs = F.softmax(logits[0], dim=-1)\n",
    "\n",
    "        next_idx = torch.multinomial(probs, 1).item()\n",
    "        next_char = itos[next_idx]\n",
    "\n",
    "        out += next_char\n",
    "        if next_char == '.':\n",
    "            break\n",
    "\n",
    "        context = context[1:] + [next_idx]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98fec8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'casalimbay.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, 'casa')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
